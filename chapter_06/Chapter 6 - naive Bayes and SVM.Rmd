---
title: "Chapter 6 - naive Bayes and SVM"
output:
  html_document:
    df_print: paged
---

# Section 6.2

Updating examples to use the newer _mlr3_ library, since _mlr_ is deprecated.

```{r, message = FALSE}
use_mlr3 <- FALSE
# install.packages("mlr3", dependencies = TRUE)
# install.packages("e1071", dependencies = TRUE)
# install.packages("mlr3learners", dependencies = TRUE)
if (use_mlr3) {
  library(mlr3)
  library(mlr3learners)
} else {
  library(mlr)
}
library(tidyverse)
```
## Section 6.2.1

### Listing 6.1
```{r}
data(HouseVotes84, package = "mlbench")
votesTib <- as_tibble(HouseVotes84)
votesTib
```
### Listing 6.2
```{r}
map_dbl(votesTib, ~sum(is.na(.)))
```
### Exercise 1
```{r}
votesTib %>% select(-Class) %>% map_dbl(~sum(which(. == "y")))
```
## Section 6.2.2

### Listing 6.3
```{r}
votesUntidy <- gather(votesTib, "Variable", "Value", -Class)
ggplot(votesUntidy, aes(Class, fill = Value)) +
  facet_wrap(~ Variable, scales = "free_y") +
  geom_bar(position = "fill") +
  theme_bw()
```
## Section 6.2.3

### Listing 6.4
```{r}
if (use_mlr3) {
  # votesTask <- makeClassifTask(data = votesTib, target = "Class")
  votesTask <- TaskClassif$new(id = "votes", backend = votesTib, target = "Class")
  # bayes <- makeLearner("classif.naiveBayes")
  bayesLearner <- lrn("classif.naive_bayes")
  bayesModel <- bayesLearner$train(votesTask)
} else {
  votesTask <- makeClassifTask(data = votesTib, target = "Class")
  bayes <- makeLearner("classif.naiveBayes")
  bayesModel <- train(bayes, votesTask)
}
```
### Listing 6.5
```{r, message = FALSE}
if (use_mlr3) {
  # todo: find mlr3 equivalent for resampling
} else {
  kFold <- makeResampleDesc(method = "RepCV", folds = 10, reps = 50, stratify = TRUE)
  bayesCV <- resample(learner = bayes, task = votesTask, resampling = kFold,
                      measures = list(mmce, acc, fpr, fnr))
  bayesCV$aggr
}
```
### Listing 6.6
```{r, message = FALSE, warning = FALSE}
politician <- tibble(V1 = "n", V2 = "n", V3 = "y", V4 = "n", V5 = "n", V6 = "y",
                     V7 = "y", V8 = "y", V9 = "y", V10 = "y", V11 = "n", V12 = "y",
                     V13 = "n", V14 = "n", V15 = "y", V16 = "n")
politicianPred <- predict(bayesModel, newdata = politician)
getPredictionResponse(politicianPred)
```
### Exercise 2
$$ p(k|x) = \frac {p(x|k) \times p(k)} {p(x)} $$
$$ posterior = \frac {likelihood \times prior} {evidence} $$
```{r, message = FALSE}
# a-priori probabilities
bayesModel$learner.model$apriori

# posterior conditional probabilities of each vote
bayesModel$learner.model$tables
```
# Section 6.5

## Section 6.5.1

### Listing 6.7

## Section 6.5.2

### Listing 6.8

### Listing 6.9

### Listing 6.10

### Listing 6.11

### Listing 6.12

### Listing 6.13

## Section 6.5.3

### Listing 6.14

# Section 6.6

## Listing 6.15

## Listing 6.16

## Exercise 3

## Exercise 4
